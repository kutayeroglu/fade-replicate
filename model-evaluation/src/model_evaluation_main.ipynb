{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdqoSgm2P_YL"
      },
      "source": [
        "# Run configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32eXIiNftqKZ",
        "outputId": "a6392b71-4c50-4da8-95cf-6f57caa0e059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOdizS9_P-hy",
        "outputId": "bb271b47-c76a-43cd-adc0-29df3b04fd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/results/20250105_164623 already exists.\n",
            "Directory /content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/results/20250105_164623/checkpoints already exists.\n",
            "Directory /content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/results/20250105_164623/plots already exists.\n",
            "Directory /content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/results/20250105_164623/metrics already exists.\n"
          ]
        }
      ],
      "source": [
        "# To be able to import .py scripts stored under src/\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/src')\n",
        "import os\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Run parameters\n",
        "model_type = \"custom_FADE\" # TODO: custom_FADE or \"baseline\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "##############################################################################\n",
        "# PATHS\n",
        "##############################################################################\n",
        "base_path = \"/content/drive/MyDrive\"\n",
        "project_dir = os.path.join(base_path, \"Colab Notebooks\", \"cmpe593\", \"term-project\")\n",
        "\n",
        "## Dataset paths\n",
        "dataset_split = \"val2017\"\n",
        "coco_base_dir = f'{base_path}/coco'\n",
        "images_dir = os.path.join(coco_base_dir, 'images', dataset_split)\n",
        "annotations_path = os.path.join(coco_base_dir,\n",
        "                                'annotations',\n",
        "                                f'instances_{dataset_split}.json')\n",
        "\n",
        "## Artifact paths (checkpoints, plots, metrics)\n",
        "timestamp = \"20250105_164623\" # TODO: Enter the timestamp of the model checkpoint you want to import\n",
        "results_dir = os.path.join(project_dir, 'results', timestamp)\n",
        "checkpoint_dir = os.path.join(results_dir, 'checkpoints')\n",
        "plot_dir = os.path.join(results_dir, 'plots')\n",
        "metrics_dir = os.path.join(results_dir, 'metrics')\n",
        "\n",
        "\n",
        "# Ensure artifact paths exist\n",
        "for dir in [results_dir, checkpoint_dir, plot_dir, metrics_dir]:\n",
        "  if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "    print(f'Directory created at {dir}')\n",
        "  else:\n",
        "    print(f'Directory {dir} already exists.')\n",
        "##############################################################################\n",
        "\n",
        "model_full_path = os.path.join(checkpoint_dir, \"model_final.pth\")\n",
        "eval_results_path = os.path.join(metrics_dir, \"evaluation_metrics.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnzQcWTDd6ps"
      },
      "source": [
        "# Main loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7F1TR_kVP7s",
        "outputId": "ddd693a9-7c2b-46f0-d95e-9ec75c9c4b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating custom FADE model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading custom FADE model weights from /content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/results/20250105_164623/checkpoints/model_final.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/src/modelops/model_loader.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom FADE model loaded.\n",
            "Loaded custom_FADE model for evaluation on cuda.\n",
            "Drive already mounted at /content/drive.\n",
            "\n",
            "Image file directory: /content/drive/MyDrive/coco/images/val2017\n",
            "Does image directory exist? True\n",
            "\n",
            "Annotation file path: /content/drive/MyDrive/coco/annotations/instances_val2017.json\n",
            "Does annotation file exist? True\n",
            "Drive already mounted at /content/drive.\n",
            "\n",
            "Generating image IDs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 5000/5000 [00:00<00:00, 1080393.59file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total of 5000 image IDs were generated.\n",
            "loading annotations into memory...\n",
            "Done (t=1.25s)\n",
            "creating index...\n",
            "index created!\n",
            "\n",
            "Dataset size is 5000\n",
            "Creating dataloader object...\n"
          ]
        }
      ],
      "source": [
        "from modelops.model_loader import load_model\n",
        "from dataops.data_loader import get_data_loader, get_ground_truth\n",
        "\n",
        "# Load the model\n",
        "model = load_model(model_type, model_full_path, device, pretrained=False)\n",
        "\n",
        "# Get data loader\n",
        "dataloader = get_data_loader(images_dir, annotations_path, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40GLgGiqYF4O",
        "outputId": "46b9ba68-e3ab-4a58-87b9-8173e9a6e97e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.88s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [11:16<00:00,  7.39it/s]\n"
          ]
        }
      ],
      "source": [
        "from modelops.inference import predict\n",
        "\n",
        "# Get predictions\n",
        "results = predict(model, dataloaders, device)\n",
        "\n",
        "# Load predictions into COCO format\n",
        "# coco _dt: detections, _gt: ground truth\n",
        "coco_gt = get_ground_truth(annotations_path)\n",
        "coco_dt = coco_gt.loadRes(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT01ILo93-7z",
        "outputId": "c0ad781d-6b6f-47dd-f6a5-cac0b1fdee99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.66s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=24.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=6.54s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.057\n"
          ]
        }
      ],
      "source": [
        "# Create COCOeval object\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "coco_evaluator = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "\n",
        "# Run evaluation\n",
        "coco_evaluator.evaluate()    # Run per-image evaluation\n",
        "coco_evaluator.accumulate()  # Aggregate the results\n",
        "coco_evaluator.summarize()   # Print the summary metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWgx7zSuR2m4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61caa1d2-4037-4c01-96b6-a4048be36b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics saved to /content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/results/20250105_164623/metrics/evaluation_metrics.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# Extract key metrics from COCOeval\n",
        "coco_metrics = {\n",
        "    \"Average Precision (AP) @[IoU=0.50:0.95 | area=all | maxDets=100]\": coco_evaluator.stats[0],\n",
        "    \"Average Precision (AP) @[IoU=0.50      | area=all | maxDets=100]\": coco_evaluator.stats[1],\n",
        "    \"Average Precision (AP) @[IoU=0.75      | area=all | maxDets=100]\": coco_evaluator.stats[2],\n",
        "    \"Average Precision (AP) @[IoU=0.50:0.95 | area=small | maxDets=100]\": coco_evaluator.stats[3],\n",
        "    \"Average Precision (AP) @[IoU=0.50:0.95 | area=medium | maxDets=100]\": coco_evaluator.stats[4],\n",
        "    \"Average Precision (AP) @[IoU=0.50:0.95 | area=large | maxDets=100]\": coco_evaluator.stats[5],\n",
        "    \"Average Recall (AR) @[IoU=0.50:0.95 | area=all | maxDets=1]\": coco_evaluator.stats[6],\n",
        "    \"Average Recall (AR) @[IoU=0.50:0.95 | area=all | maxDets=10]\": coco_evaluator.stats[7],\n",
        "    \"Average Recall (AR) @[IoU=0.50:0.95 | area=all | maxDets=100]\": coco_evaluator.stats[8],\n",
        "    \"Average Recall (AR) @[IoU=0.50:0.95 | area=small | maxDets=100]\": coco_evaluator.stats[9],\n",
        "    \"Average Recall (AR) @[IoU=0.50:0.95 | area=medium | maxDets=100]\": coco_evaluator.stats[10],\n",
        "    \"Average Recall (AR) @[IoU=0.50:0.95 | area=large | maxDets=100]\": coco_evaluator.stats[11],\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open(eval_results_path, \"w\") as f:\n",
        "    json.dump(coco_metrics, f, indent=4)\n",
        "\n",
        "print(f\"Evaluation metrics saved to {eval_results_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl168rJW7bo4",
        "outputId": "f97abe18-51aa-451f-d9da-7d0768971b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'image_id': 139, 'category_id': 1, 'bbox': [335.3409118652344, 184.2754364013672, 127.52828979492188, 138.2395477294922], 'score': 0.1523757427930832, 'segmentation': [[335.3409118652344, 184.2754364013672, 335.3409118652344, 322.5149841308594, 462.86920166015625, 322.5149841308594, 462.86920166015625, 184.2754364013672]], 'area': 17629.453103965614, 'id': 1, 'iscrowd': 0}, {'image_id': 139, 'category_id': 1, 'bbox': [364.6128845214844, 223.4462432861328, 115.8565673828125, 142.7678985595703], 'score': 0.14644700288772583, 'segmentation': [[364.6128845214844, 223.4462432861328, 364.6128845214844, 366.2141418457031, 480.4694519042969, 366.2141418457031, 480.4694519042969, 223.4462432861328]], 'area': 16540.598659569398, 'id': 2, 'iscrowd': 0}, {'image_id': 139, 'category_id': 1, 'bbox': [276.9834289550781, 209.77529907226562, 138.9505615234375, 151.67990112304688], 'score': 0.14604786038398743, 'segmentation': [[276.9834289550781, 209.77529907226562, 276.9834289550781, 361.4552001953125, 415.9339904785156, 361.4552001953125, 415.9339904785156, 209.77529907226562]], 'area': 21076.00743286684, 'id': 3, 'iscrowd': 0}, {'image_id': 139, 'category_id': 1, 'bbox': [260.7035217285156, 187.41854858398438, 118.7919921875, 126.1197509765625], 'score': 0.1425986886024475, 'segmentation': [[260.7035217285156, 187.41854858398438, 260.7035217285156, 313.5382995605469, 379.4955139160156, 313.5382995605469, 379.4955139160156, 187.41854858398438]], 'area': 14982.016472697258, 'id': 4, 'iscrowd': 0}, {'image_id': 139, 'category_id': 1, 'bbox': [334.6036376953125, 122.29469299316406, 210.81414794921875, 278.064453125], 'score': 0.13756239414215088, 'segmentation': [[334.6036376953125, 122.29469299316406, 334.6036376953125, 400.35914611816406, 545.4177856445312, 400.35914611816406, 545.4177856445312, 122.29469299316406]], 'area': 58619.92076051235, 'id': 5, 'iscrowd': 0}]\n"
          ]
        }
      ],
      "source": [
        "print(results[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GveiTkQu8Dni",
        "outputId": "c1135dff-ba5f-41d6-ee1e-0b0ecda235ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned Results: [{'image_id': 139, 'category_id': 1, 'bbox': [335.3409118652344, 184.2754364013672, 127.52828979492188, 138.2395477294922], 'score': 0.1523757427930832}, {'image_id': 139, 'category_id': 1, 'bbox': [364.6128845214844, 223.4462432861328, 115.8565673828125, 142.7678985595703], 'score': 0.14644700288772583}, {'image_id': 139, 'category_id': 1, 'bbox': [276.9834289550781, 209.77529907226562, 138.9505615234375, 151.67990112304688], 'score': 0.14604786038398743}, {'image_id': 139, 'category_id': 1, 'bbox': [260.7035217285156, 187.41854858398438, 118.7919921875, 126.1197509765625], 'score': 0.1425986886024475}, {'image_id': 139, 'category_id': 1, 'bbox': [334.6036376953125, 122.29469299316406, 210.81414794921875, 278.064453125], 'score': 0.13756239414215088}]\n"
          ]
        }
      ],
      "source": [
        "cleaned_results = [\n",
        "    {\n",
        "        \"image_id\": r[\"image_id\"],\n",
        "        \"category_id\": r[\"category_id\"],\n",
        "        \"bbox\": r[\"bbox\"],\n",
        "        \"score\": r[\"score\"]\n",
        "    }\n",
        "    for r in results\n",
        "]\n",
        "\n",
        "print(\"Cleaned Results:\", cleaned_results[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBbYSH-I8guP",
        "outputId": "7dc34f0e-c5f9-431d-e93b-1c6e9206bd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=1.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=22.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.68s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n"
          ]
        }
      ],
      "source": [
        "coco_dt = coco_gt.loadRes(cleaned_results)\n",
        "coco_evaluator = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "coco_evaluator.evaluate()\n",
        "coco_evaluator.accumulate()\n",
        "coco_evaluator.summarize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip9CamNz-qjr",
        "outputId": "438692b4-7156-437b-9f5d-5e0f4b6332a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Results Count: 0\n"
          ]
        }
      ],
      "source": [
        "confidence_threshold = 0.5\n",
        "filtered_results = [\n",
        "    r for r in cleaned_results if r['score'] > confidence_threshold\n",
        "]\n",
        "\n",
        "print(\"Filtered Results Count:\", len(filtered_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyiQlYY-_KCl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}