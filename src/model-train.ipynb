{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sQGc6ui7dVZ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65LrxLAzpAMP",
    "outputId": "4e60dbe0-a4a8-457d-b670-64af0dc395c9"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version is {sys.version}\")\n",
    "\n",
    "import torch\n",
    "print(f\"Torch version is {torch.__version__}\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgeMoC54dG9A"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
    "from torchvision.models.detection.rpn import AnchorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpNsbVMu7aEq"
   },
   "source": [
    "# Helpers, utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgTF-U0tAe7u",
    "outputId": "69f29073-b665-4c10-a9a8-4bf2647b8ded"
   },
   "outputs": [],
   "source": [
    "# Ensure forward pass stability of the model\n",
    "def test_model(input_type=\"real\"):\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  # Change to random noise if prompted\n",
    "  if input_type == \"noise\":\n",
    "    sample_input = torch.randn(3, 800, 800)\n",
    "    sample_input = sample_input.to(device)\n",
    "  elif input_type == \"real\": # TODO: Implement\n",
    "    pass\n",
    "\n",
    "  with torch.no_grad():\n",
    "      outputs = model([sample_input])\n",
    "\n",
    "  print(f'Model output for input type: {input_type}')\n",
    "  print(outputs)\n",
    "\n",
    "test_model(input_type=\"noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdcnStBaIYZR"
   },
   "source": [
    "## Inspect a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5O7VYBWzG_Tl",
    "outputId": "4346e654-2670-45b6-e9dc-15a9b71f18bd"
   },
   "outputs": [],
   "source": [
    "def inspect_sample(dataset, index):\n",
    "  # Load a sample from the dataset\n",
    "  img, target = dataset[index]\n",
    "\n",
    "  # Verify the image\n",
    "  print(f\"Image shape: {img.shape}\")  # Should be [C, H, W]\n",
    "  print(f\"Image dtype: {img.dtype}\")  # Should be torch.float32\n",
    "\n",
    "  # Verify the target\n",
    "  print(f\"\\nTarget keys: {target.keys()}\")\n",
    "\n",
    "  # Verify the bounding boxes\n",
    "  print(f\"\\nBoxes: {target['boxes']}\")\n",
    "  print(f\"Boxes shape: {target['boxes'].shape}\")\n",
    "\n",
    "  # Verify the labels\n",
    "  print(f\"\\nLabels: {target['labels']}\")\n",
    "  print(f\"Labels shape: {target['labels'].shape}\")\n",
    "\n",
    "  # Verify other target fields\n",
    "  print(f\"\\nImage ID: {target['image_id']}\")\n",
    "  print(f\"Area: {target['area']}\")\n",
    "  print(f\"Iscrowd: {target['iscrowd']}\")\n",
    "\n",
    "inspect_sample(train_dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTNacjfYAqE0"
   },
   "outputs": [],
   "source": [
    "# TODO: debug: for checking validity of bounding box bounds\n",
    "# def validate_bboxes_subset(dataset, sample_size=2000):\n",
    "#     \"\"\"\n",
    "#     Checks a random subset of the dataset to ensure bounding boxes are valid.\n",
    "#     sample_size: how many samples to validate\n",
    "#     \"\"\"\n",
    "#     num_samples = len(dataset)\n",
    "#     sampled_indices = random.sample(range(num_samples), min(sample_size, num_samples))\n",
    "\n",
    "#     invalid_samples = []\n",
    "#     for idx in tqdm(sampled_indices, desc=\"Validating bounding boxes (subset)\", unit=\"sample\"):\n",
    "#         img, target = dataset[idx]\n",
    "\n",
    "#         # get image dimensions\n",
    "#         _, img_height, img_width = img.shape\n",
    "#         boxes = target['boxes'].cpu()\n",
    "\n",
    "#         if boxes.size(0) == 0:\n",
    "#             continue\n",
    "\n",
    "#         widths = boxes[:, 2] - boxes[:, 0]\n",
    "#         heights = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "#         invalid_mask = (\n",
    "#             (widths <= 0) |\n",
    "#             (heights <= 0) |\n",
    "#             (boxes[:, 0] < 0) |\n",
    "#             (boxes[:, 1] < 0) |\n",
    "#             (boxes[:, 2] > img_width) |\n",
    "#             (boxes[:, 3] > img_height)\n",
    "#         )\n",
    "\n",
    "#         if invalid_mask.any():\n",
    "#             invalid_samples.append(idx)\n",
    "\n",
    "#     if invalid_samples:\n",
    "#         print(\"Found invalid bounding boxes in these samples:\", invalid_samples)\n",
    "#     else:\n",
    "#         print(f\"\\nNo invalid bounding boxes found in this random subset of {len(sampled_indices)} samples.\")\n",
    "\n",
    "#     return invalid_samples\n",
    "\n",
    "\n",
    "# invalid_samples = validate_bboxes_subset(train_dataset, sample_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4OWJk35IcHg"
   },
   "source": [
    "\n",
    "## Visualize the Image and Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "tma-82bBHB1Z",
    "outputId": "0a5e6de4-1e0c-4b78-ac46-598575b07b9c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_image_with_boxes(img, target):\n",
    "    # Convert the image tensor to a NumPy array and transpose to [H, W, C]\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(img_np)\n",
    "\n",
    "    boxes = target['boxes']\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        rect = patches.Rectangle(\n",
    "            (xmin, ymin), width, height,\n",
    "            linewidth=1, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Fetch a random sample from the dataset\n",
    "random_index = random.randint(0, len(train_dataset))\n",
    "img, target = train_dataset[random_index]\n",
    "\n",
    "# Visualize the sample\n",
    "visualize_image_with_boxes(img, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDRxzIqkIfNx"
   },
   "source": [
    "## Test-Fetch Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7Vy40MGOX--",
    "outputId": "18304dcd-04bc-46a3-b3ca-d0ead1afc9f1"
   },
   "outputs": [],
   "source": [
    "# Fetch multiple batches to ensure consistency\n",
    "for _ in range(5):\n",
    "    images, targets = next(iter(train_loader))\n",
    "    print(f\"Number of images: {len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSn6rz7VKtTy",
    "outputId": "519456ed-0767-48db-ed4b-60c59a8a46df"
   },
   "outputs": [],
   "source": [
    "# Fetch a batch\n",
    "images, targets = next(iter(train_loader))\n",
    "\n",
    "# Verify the batch\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Image 0 shape: {images[0].shape}\")\n",
    "print(f\"Image 1 shape: {images[1].shape}\")\n",
    "print(f\"Target 0 keys: {targets[0].keys()}\")\n",
    "print(f\"Target 1 keys: {targets[1].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRrYW3XoYo48"
   },
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOATFzycZETt"
   },
   "source": [
    "## Run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17821,
     "status": "ok",
     "timestamp": 1736169160193,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "Q2NcuiVOZHHN",
    "outputId": "99bc7456-3755-41db-a7db-830a6e0d39b4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4486,
     "status": "ok",
     "timestamp": 1736169169690,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "4r3xFKc6Yoet",
    "outputId": "8d87817f-9f6c-4860-9949-aa62d602acdb"
   },
   "outputs": [],
   "source": [
    "# To be able to import .py scripts stored under src/\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks/cmpe593/term-project/src')\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Run parameters\n",
    "model_type = \"custom_FADE\" # TODO: custom_FADE or \"baseline\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##############################################################################\n",
    "# PATHS\n",
    "##############################################################################\n",
    "base_path = \"/content/drive/MyDrive\"\n",
    "project_dir = os.path.join(base_path, \"Colab Notebooks\", \"cmpe593\", \"term-project\")\n",
    "\n",
    "## Dataset paths\n",
    "dataset_split = \"train2017\" # TODO: pick from (\"train2017\", \"val2017\")\n",
    "coco_base_dir = f'{base_path}/coco'\n",
    "images_dir = os.path.join(coco_base_dir, 'images', dataset_split)\n",
    "annotations_path = os.path.join(coco_base_dir,\n",
    "                                'annotations',\n",
    "                                f'instances_{dataset_split}.json')\n",
    "\n",
    "## Artifact paths (checkpoints, plots, metrics)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = os.path.join(project_dir, 'results', timestamp)\n",
    "checkpoint_dir = os.path.join(results_dir, 'checkpoints')\n",
    "plot_dir = os.path.join(results_dir, 'plots')\n",
    "metrics_dir = os.path.join(results_dir, 'metrics')\n",
    "\n",
    "\n",
    "# Ensure artifact paths exist\n",
    "for dir in [results_dir, checkpoint_dir, plot_dir, metrics_dir]:\n",
    "  if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "    print(f'Directory created at {dir}')\n",
    "  else:\n",
    "    print(f'Directory {dir} already exists.')\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbCJxQTXyp4G"
   },
   "source": [
    "## Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98035,
     "status": "ok",
     "timestamp": 1736169477550,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "Fc7LWgf1dEN0",
    "outputId": "dc7c29e8-2c7e-4012-8705-ef8d69a1bdaf"
   },
   "outputs": [],
   "source": [
    "from dataops.data_loader import get_data_loader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def get_num_classes(dataloader):\n",
    "    \"\"\"\n",
    "    Retrieve the number of classes from the dataset used by the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): PyTorch DataLoader object.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of classes.\n",
    "    \"\"\"\n",
    "    # Access the original dataset\n",
    "    dataset = dataloader.dataset.dataset if isinstance(dataloader.dataset, Subset) else dataloader.dataset\n",
    "\n",
    "    # Retrieve category IDs\n",
    "    category_ids = dataset.cat_ids\n",
    "    print(f\"Number of categories: {len(category_ids)}\")\n",
    "    return len(category_ids), category_ids\n",
    "\n",
    "\n",
    "# Get data loader and number of classes inside the dataset\n",
    "dataloader = get_data_loader(images_dir, annotations_path, train=True, subset=True, subset_size=10000)\n",
    "num_classes, category_ids = get_num_classes(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16229,
     "status": "ok",
     "timestamp": 1736169493772,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "cKsOalAocQYp",
    "outputId": "460a8709-884e-4493-f2cd-df718257ecfe"
   },
   "outputs": [],
   "source": [
    "from modelops import model_loader\n",
    "\n",
    "model = model_loader.load_model(\n",
    "    model_type=model_type,\n",
    "    device=device,\n",
    "    eval_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50USW5pQ8iAo"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsJMwYFzXmwk"
   },
   "source": [
    "### Set parameters and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1736170732782,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "NPzxwTn142EU",
    "outputId": "0709fac4-83a3-40ae-9159-5bbbdf2b5027"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR\n",
    "\n",
    "# Set hyperparameters\n",
    "num_classes = len(category_ids) + 1  # +1 for background\n",
    "quick_experiment = False\n",
    "hyperparam_key = 'quick_experiment' if quick_experiment else 'longer_experiment'\n",
    "\n",
    "hyperparameters = {\n",
    "    # Quick experiment is for sanity check\n",
    "    'quick_experiment': {\n",
    "        'lr_scheduler': None,\n",
    "        'lr': 0.01,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'num_epochs': 3,\n",
    "    },\n",
    "\n",
    "    'longer_experiment': {\n",
    "        'lr_scheduler': 'warmup + stepLR@ep3',\n",
    "        'lr': 0.01,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'num_epochs': 10,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Extract hyperparameters\n",
    "active_hparams = hyperparameters[hyperparam_key]\n",
    "lr = active_hparams['lr']\n",
    "momentum = active_hparams['momentum']\n",
    "weight_decay = active_hparams['weight_decay']\n",
    "num_epochs = active_hparams['num_epochs']\n",
    "\n",
    "# Initialize model parameters that require gradients\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(\n",
    "    params,\n",
    "    lr=lr,  # Applies to all parameters\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "def warmup_schedule(epoch):\n",
    "    warmup_epochs = 3\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs  # Start from a small value and scale up\n",
    "    return 1.0  # Maintain full learning rate after warm-up\n",
    "\n",
    "# Apply the scheduler\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda=warmup_schedule)\n",
    "\n",
    "# Print learning rate for debugging\n",
    "print(\"Learning Rate Scheduler Test:\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}: LR = {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-Lm0GYMXutR"
   },
   "source": [
    "### Save params for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1736170743178,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "3ZKqIqvwXRsx",
    "outputId": "814b2fd3-014d-4c5d-9101-af5fec30f801"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to save the hyperparameters file\n",
    "hyperparams_path = os.path.join(results_dir, \"hyperparameters.json\")\n",
    "active_hparams['model_type'] = f'{model_type}-{model.__class__.__name__}'\n",
    "\n",
    "# Save hyperparameters\n",
    "with open(hyperparams_path, \"w\") as f:\n",
    "    json.dump(active_hparams, f, indent=4)\n",
    "\n",
    "print(f\"Hyperparameters saved to {hyperparams_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDACYS3HPNhL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    drive_checkpoint_dir,\n",
    "    lr_scheduler=None,\n",
    "    val_loader=None,\n",
    "):\n",
    "  epoch_losses = []\n",
    "  batch_losses = [] # Track batch-level losses\n",
    "  error_batches = []  # To store details of failing batches for debug\n",
    "  ap_history = []     # To store AP metrics after each epoch\n",
    "\n",
    "  # File paths for saving loss data\n",
    "  epoch_loss_file = os.path.join(drive_checkpoint_dir, \"epoch_losses.txt\")\n",
    "  batch_loss_file = os.path.join(drive_checkpoint_dir, \"batch_losses.txt\")\n",
    "\n",
    "  # Initialize StepLR scheduler for dynamic adjustment after warm-up\n",
    "  post_warmup_scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    batch_count = 0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print('-' * 20)\n",
    "\n",
    "    # Training loop\n",
    "    for images, targets, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}\", unit=\"batch\"):\n",
    "      batch_count += 1\n",
    "\n",
    "      # Move images and targets to the device\n",
    "      images = [img.to(device) for img in images]\n",
    "      targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "      try:\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "      except AssertionError as e:\n",
    "        print(f\"\\n[ERROR] Bounding box error in batch {batch_count}!\")\n",
    "        batch_error_info = {\"epoch\": epoch+1, \"batch_idx\": batch_count, \"boxes\": []}\n",
    "\n",
    "        for i, tgt in enumerate(targets):\n",
    "          batch_error_info[\"boxes\"].append(tgt['boxes'].cpu().tolist())\n",
    "\n",
    "        error_batches.append(batch_error_info)\n",
    "        continue\n",
    "\n",
    "      # Compute total loss\n",
    "      losses = sum(loss for loss in loss_dict.values())\n",
    "      loss_value = losses.item()\n",
    "      epoch_loss += loss_value\n",
    "      batch_losses.append(loss_value)  # Track batch loss\n",
    "\n",
    "      # Backward pass and optimization\n",
    "      optimizer.zero_grad()\n",
    "      losses.backward()\n",
    "\n",
    "      # Monitor gradient norms\n",
    "      total_grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "      print(f\"Batch {batch_count}, Gradient Norm: {total_grad_norm:.6f}\")\n",
    "      optimizer.step()\n",
    "\n",
    "\n",
    "      # Display intermediate losses\n",
    "      if batch_count % 200 == 0:\n",
    "        print(f\"Batch {batch_count}, Loss: {loss_value:.4f}\")\n",
    "\n",
    "\n",
    "    # Transition from warm-up to StepLR after the warm-up phase\n",
    "    if epoch == 3:\n",
    "      print(f\"Transitioning from warm-up to StepLR at learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "      lr_scheduler = post_warmup_scheduler\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    if lr_scheduler:\n",
    "      lr_scheduler.step()\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    epoch_duration = time.time() - start_time\n",
    "    average_epoch_loss = epoch_loss / len(train_loader)\n",
    "    epoch_losses.append(average_epoch_loss)\n",
    "\n",
    "    # Save epoch summary\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed in {str(datetime.timedelta(seconds=int(epoch_duration)))}\")\n",
    "    print(f\"Average Loss: {average_epoch_loss:.4f}\")\n",
    "    print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    drive_checkpoint_path = os.path.join(drive_checkpoint_dir, f'model_epoch_{epoch + 1}.pth')\n",
    "    torch.save(model.state_dict(), drive_checkpoint_path)\n",
    "    print(f\"Checkpoint saved to Google Drive at {drive_checkpoint_path}\")\n",
    "\n",
    "  # =========================\n",
    "  # Training loop completes\n",
    "  # =========================\n",
    "  print(\"Training loop finished.\")\n",
    "\n",
    "  # Save the model state dictionary\n",
    "  drive_final_checkpoint_path = os.path.join(drive_checkpoint_dir, 'model_final.pth')\n",
    "  torch.save(model.state_dict(), drive_final_checkpoint_path)\n",
    "  print(f\"Final model saved to Google Drive at {drive_final_checkpoint_path}\")\n",
    "\n",
    "  # Save and display the training loss plot\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  plot_filename_drive = os.path.join(plot_dir, 'training_loss_plot.png')\n",
    "  plt.figure()\n",
    "  plt.plot(range(1, num_epochs + 1), epoch_losses, marker='o')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Average Loss')\n",
    "  plt.title('Training Loss Over Epochs')\n",
    "  plt.grid(True)\n",
    "  plt.savefig(plot_filename_drive)\n",
    "  print(f\"Training loss plot saved to Google Drive at {plot_filename_drive}\")\n",
    "  plt.show()\n",
    "\n",
    "  if error_batches:\n",
    "      print(\"\\nSome batches triggered bounding box assertions. Their info:\")\n",
    "      for info in error_batches:\n",
    "          print(f\"Epoch {info['epoch']}, Batch {info['batch_idx']}, Boxes: {info['boxes']}\")\n",
    "  else:\n",
    "      print(\"No bounding box errors encountered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1lsi99bMhHnF6oe5vUl9Ljyfd_i2f3WHX"
    },
    "id": "0xz9IwfpY4ck",
    "outputId": "48a1dc07-d03d-4b0f-b2fd-a5dd006e7f71"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    drive_checkpoint_dir=checkpoint_dir,\n",
    "    val_loader=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt6aVePHsJxV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6sQGc6ui7dVZ",
    "fpNsbVMu7aEq",
    "hdcnStBaIYZR"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
